{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## General Colab Tips\n",
        "- Modify files by opening/editing them in the UI (double-click to open).\n",
        "- `Right click > Refresh` in the Colab file explorer to update the directory.\n",
        "- All files are lost when the Colab session disconnects, so make sure back up your work.\n",
        "- Do **not** use `drive.mount` for your datasets! Reading from GDrive is super slow.\n",
        "- Instead, place datasets into the `/content/` folder and modify your data accordingly.\n",
        "\n",
        "**Make a copy of this notebook and modify this to whatever workflow you prefer!**\n",
        "\n",
        "If you have some additional colab tips, please share them on the discussion forum.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, enable a GPU runtime via `Runtime > Change runtime type > T4 GPU`\n",
        "\n",
        "Next, upload the your project files to the Colab. You can do this by either\n",
        "- using Github (**recommended**)\n",
        "- uploading files manually using the UI\n",
        "\n",
        "## Github Setup\n",
        "\n",
        "You can use git from within Google Colab!\n",
        "\n",
        "For this section, we assume you know how to use git and have already pushed the starter code to a private repo.\n",
        "\n",
        "Before you continue, make sure you download and push the starter code to your repo.  \n",
        "It's a good idea to structure your repo something like\n",
        "```\n",
        "online_deep_learning/\n",
        "    homework1/\n",
        "    homework2/\n",
        "    ...\n",
        "```\n",
        "\n",
        "We highly recommend using this workflow as you'll be able to easily pull/commit your changes after modifying your model on Colab.\n",
        "\n",
        "To do this, you'll need a personal access token from [https://github.com/settings/tokens](https://github.com/settings/tokens)\n",
        "\n",
        "The easiest thing to do is select \"classic\" token and make sure you have the `repo` scope selected to allow access to your private repos.\n",
        "There's also fine-grained tokens where you can select access to specific repos.\n",
        "\n",
        "Once you have your token, fill in your information and then run the following cell to clone your git repo to the Colab instance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Fill in your GitHub credentials\n",
        "os.environ['USER'] = 'YOUR_GITHUB_USERNAME'\n",
        "os.environ['REPO'] = 'YOUR_REPO_NAME'\n",
        "os.environ['TOKEN'] = 'YOUR_GITHUB_TOKEN'\n",
        "\n",
        "# do everything in colab's \"root\" directory\n",
        "%cd /content\n",
        "!git clone https://${TOKEN}@github.com/${USER}/${REPO}.git\n",
        "\n",
        "# make sure your repo shows up\n",
        "%ls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Code Setup\n",
        "\n",
        "Move into `homework5/` so we can continue setting up the data / code for training.\n",
        "\n",
        "This will be the main working directory and the training/grading must be run from this directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# navigate to your repo\n",
        "%cd /content/{os.environ['REPO']}\n",
        "%ls\n",
        "\n",
        "# go to a specific homework\n",
        "%cd homework5\n",
        "%ls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies\n",
        "\n",
        "Install the required packages for Homework 5.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch (Colab usually has it, but this ensures latest version)\n",
        "# Check https://pytorch.org/get-started/locally/ for the latest command\n",
        "# For Colab, CUDA is usually available, so we install CUDA version\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install other dependencies\n",
        "%pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Setup\n",
        "\n",
        "Now that your code is all ready, the next step is to download the datasets.\n",
        "\n",
        "Note: it's good practice to add data directories like `data/` to your `.gitignore` so you don't accidentally commit them to your repo.\n",
        "\n",
        "Since the datasets used in this class are relatively small, we can simply re-download them if the compute instance crashes/restarts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and extract the SuperTuxKart image dataset\n",
        "!wget https://utexas.box.com/shared/static/qubjm5isldqvyimfj9rsmbnvnbezwcv4.zip -O supertux_data.zip\n",
        "!unzip -q supertux_data.zip -d data/\n",
        "\n",
        "# Verify the data structure\n",
        "%ls data/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Implementation + Training\n",
        "\n",
        "Now you should be all set up.\n",
        "Next, you'll need to implement:\n",
        "- `homework/ae.py` - Patch-level auto-encoder\n",
        "- `homework/bsq.py` - Binary Spherical Quantization\n",
        "- `homework/autoregressive.py` - Auto-regressive model\n",
        "- `homework/generation.py` - Generation function (already provided)\n",
        "\n",
        "And then you're ready to train!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pull latest changes from your repo\n",
        "!git pull origin main\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train PatchAutoEncoder (Part 1)\n",
        "# This trains a patch-level auto-encoder\n",
        "!python -m homework.train PatchAutoEncoder --epochs 5 --batch_size 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train BSQPatchAutoEncoder (Part 2)\n",
        "# This combines your auto-encoder with Binary Spherical Quantization\n",
        "# Make sure to use patch_size=5 and codebook_bits=10 for compatibility\n",
        "!python -m homework.train BSQPatchAutoEncoder --epochs 5 --batch_size 64\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenization\n",
        "\n",
        "After training the BSQPatchAutoEncoder, we need to tokenize the training and validation datasets.\n",
        "\n",
        "**Important:** Replace `YOUR_BSQPatchAutoEncoder.pth` with the actual checkpoint filename from the `checkpoints/` directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List available checkpoints to find your BSQPatchAutoEncoder\n",
        "!ls -lh checkpoints/ | grep BSQPatchAutoEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenize the training set\n",
        "# Replace the checkpoint path with your actual checkpoint filename\n",
        "!python -m homework.tokenize checkpoints/YOUR_BSQPatchAutoEncoder.pth data/tokenized_train.pth data/train/\n",
        "\n",
        "# Tokenize the validation set\n",
        "!python -m homework.tokenize checkpoints/YOUR_BSQPatchAutoEncoder.pth data/tokenized_valid.pth data/valid/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the size of tokenized datasets\n",
        "!du -hs data/tokenized_train.pth data/tokenized_valid.pth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train AutoregressiveModel (Part 3)\n",
        "# This trains the auto-regressive transformer on tokenized images\n",
        "!python -m homework.train AutoregressiveModel --epochs 5 --batch_size 64\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generation (Part 4)\n",
        "\n",
        "Generate samples from your trained models.\n",
        "\n",
        "**Important:** Replace the checkpoint paths with your actual checkpoint filenames.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List available checkpoints\n",
        "!ls -lh checkpoints/ | tail -10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate images\n",
        "# Replace checkpoint paths with your actual filenames\n",
        "# Format: tokenizer_checkpoint autoregressive_checkpoint num_images output_dir\n",
        "!python -m homework.generation checkpoints/YOUR_BSQPatchAutoEncoder.pth checkpoints/YOUR_AutoregressiveModel.pth 10 generations/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display generated images\n",
        "from IPython.display import Image, display\n",
        "from pathlib import Path\n",
        "\n",
        "generation_dir = Path(\"generations\")\n",
        "if generation_dir.exists():\n",
        "    for img_path in sorted(generation_dir.glob(\"*.png\")):\n",
        "        print(img_path)\n",
        "        display(Image(str(img_path)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grader\n",
        "\n",
        "Run the following cell to grade your homework.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure you're in the homework5 directory\n",
        "%cd /content/{os.environ['REPO']}/homework5\n",
        "\n",
        "# Run the grader\n",
        "!python3 -m grader homework -vv --disable_color\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Update your changes\n",
        "\n",
        "Commit and push your code changes to GitHub.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/{os.environ['REPO']}/homework5\n",
        "%ls\n",
        "!git status\n",
        "\n",
        "# Be careful not to \"git add *\" since there are datasets and logs\n",
        "!git add homework/*.py\n",
        "!git config --global user.email \"YOUR_GITHUB_EMAIL\"\n",
        "!git config --global user.name \"YOUR_GITHUB_USERNAME\"\n",
        "!git commit -m \"Homework 5 implementation\"\n",
        "!git push origin main\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submission\n",
        "\n",
        "Run the following cell to bundle your submission (modify UTID accordingly).\n",
        "\n",
        "If you notice that your bundle is too large, you can modify the `bundle.py` script and ignore large files by adding them manually to `BLACKLIST`.\n",
        "\n",
        "After the bundler and grader run, right click and download your bundled `.zip` file from the Colab UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure you're in the homework5 directory\n",
        "%cd /content/{os.environ['REPO']}/homework5\n",
        "\n",
        "# Replace YOUR_UT_ID with your actual UT ID\n",
        "!python3 bundle.py homework YOUR_UT_ID\n",
        "\n",
        "# Check the bundle was created\n",
        "!ls -lh YOUR_UT_ID.zip\n",
        "\n",
        "# Optional: run the grader with your bundled homework to double check\n",
        "# !python3 -m grader YOUR_UT_ID.zip -vv --disable_color\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the bundle\n",
        "from google.colab import files\n",
        "files.download(f\"/content/{os.environ['REPO']}/homework5/YOUR_UT_ID.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tensorboard (Optional)\n",
        "\n",
        "Monitor your training progress with TensorBoard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
